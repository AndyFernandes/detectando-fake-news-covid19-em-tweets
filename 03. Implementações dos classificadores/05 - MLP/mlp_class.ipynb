{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mlp_class.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zv58wHl1Y-BT","colab_type":"text"},"source":["Implementação\n"]},{"cell_type":"code","metadata":{"id":"a-k1FjcVx_4d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596073073137,"user_tz":180,"elapsed":1420,"user":{"displayName":"Carolina Alves Ribeiro","photoUrl":"https://lh6.googleusercontent.com/-PqVNf9mWVxc/AAAAAAAAAAI/AAAAAAAAAJ4/QbFQ4QxVm3g/s64/photo.jpg","userId":"07105028147325403239"}}},"source":["import math\n","import numpy as np\n","import operator\n","\n","class MLP():\n","  def __init__(self, input_nodes=1, learning_rate=1e-03, function=\"sigmoid\") -> None:\n","    self.number_of_nodes = []\n","    self.number_of_nodes.append(input_nodes)\n","    self.weights = []\n","    self.biases = []\n","    self.function = function\n","    self.learning_rate = learning_rate\n","\n","\n","  # Definição das funções custo\n","  @staticmethod\n","  def soft_plus(x):\n","      sp = np.vectorize(lambda y: math.log(1 + math.exp(y)))\n","      return sp(x)\n","\n","  @staticmethod\n","  def relu(x):\n","      re = np.vectorize(lambda y: max(0, y))\n","      return re(x)\n","\n","  @staticmethod\n","  def sigmoid(x):\n","      sig = np.vectorize(lambda y:  (1 - 1 / (1 + math.exp(y))) if y < 0 else  (1 / (1 + math.exp(-y))))\n","      return sig(x)\n","\n","  # Método para aplicar as funções sigmoidais, soft_plus e relu\n","  @staticmethod\n","  def apply_function(x,function):\n","    if function == \"sigmoid\":\n","        return MLP.sigmoid(x)\n","    elif function == \"soft_plus\":\n","        return MLP.soft_plus(x)\n","    elif function == \"relu\":\n","        return MLP.relu(x)\n","\n","  # Método de cálculo da derivada\n","  @staticmethod\n","  def derivative(x, function):\n","     if function == \"sigmoid\":\n","        return np.multiply(x, (1-x))\n","     elif function == \"soft_plus\":\n","        return MLP.sigmoid(x)\n","     elif function == \"relu\":\n","        d_relu = np.vectorize(lambda y: 1 if y > 0 else 0)\n","        return d_relu(x)\n","\n","  # Método auxiliar para adicionar camadas ocultas\n","  def add_layer(self, number_of_nodes: int, weights=None, bias=None):\n","    self.number_of_nodes.append(number_of_nodes)\n","    if not weights is None:\n","        self.weights.append(weights)\n","    elif len(self.number_of_nodes) > 1:\n","        self.weights.append(np.random.randn(self.number_of_nodes[-1], self.number_of_nodes[-2]) * np.sqrt(2 / (self.number_of_nodes[-1] + self.number_of_nodes[-2])))\n","\n","    if not bias is None:\n","        self.biases.append(bias)\n","    elif len(self.number_of_nodes) > 1:\n","        self.biases.append(np.random.uniform(0, 0, size=(number_of_nodes, 1)))\n","\n","\n","  # Definição da função de feed_forward\n","  def feed_forward(self, inp):\n","    out = [np.matrix(inp).T]\n","\n","    for i in range(len(self.number_of_nodes) - 1):\n","      y_hat = np.dot(self.weights[i], out[-1]) + self.biases[i]\n","      out.append(MLP.apply_function(y_hat, self.function))\n","    return out\n","\n","\n","  # Aplica o gradiente descendente no passo de trainemtn\n","  def train_gradient(self, y, out, errors):\n","      for i in range(len(self.weights)):\n","          # Calcula o gradiente e a correção dos pesos\n","          grad = np.multiply(errors[-1-i], MLP.derivative(out[-1-i], self.function))\n","          grad *= self.learning_rate\n","          self.biases[-1-i] += grad\n","          delta_w  = np.dot(grad, out[-2-i].T)\n","          self.weights[-1-i] += delta_w\n","\n","      return self.weights\n","\n","\n","  # Método de treinamento\n","  def train(self, inp, y, type='gradient'):\n","    y = np.matrix(y).T\n","    out = self.feed_forward(inp)\n","    errors = [np.subtract(y, out[-1])]\n","\n","    for i in range(len(self.weights) - 1):\n","        errors.insert(0, np.dot(self.weights[-1-i].T, errors[0]))\n","\n","    if type == 'gradient':\n","      return self.train_gradient(y, out, errors)\n","\n","  # Método de predição\n","  def predict(self, inp):\n","    out = self.feed_forward(inp)[-1]\n","    out = dict(enumerate(out.A1))\n","    out_class = max(out.items(), key=operator.itemgetter(1))[0]\n","    out_prob = out[out_class]\n","    return out_class, out_prob\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PvCeRd5xZDAZ","colab_type":"text"},"source":["Explicação do uso\n"]},{"cell_type":"code","metadata":{"id":"W8ss7IzzzZPS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"error","timestamp":1596073090053,"user_tz":180,"elapsed":1323,"user":{"displayName":"Carolina Alves Ribeiro","photoUrl":"https://lh6.googleusercontent.com/-PqVNf9mWVxc/AAAAAAAAAAI/AAAAAAAAAJ4/QbFQ4QxVm3g/s64/photo.jpg","userId":"07105028147325403239"}},"outputId":"f24c478b-4df0-4479-bfe0-9936e596f0f7"},"source":["# Inicializando a rede com dois nós de entrada e taxa de aprendizagem igual a 0.2\n","# Adicionando duas camadas com 2 nós cada.\n","mlp = MLP(input_nodes=2, learning_rate=.2)\n","mlp.add_layer(2)\n","mlp.add_layer(2)\n","\n","# Carregue o array de entrada e saída aqui\n","input = []\n","y = []\n","\n","epoch = 2000\n","# Depois faça as iterações de treinamento pelas épocas\n","for i in range(epoch):\n","  data = 'random data'\n","  mlp.train(input, y)\n","\n","# Vetor xi com entradas não conhecidas\n","xi = []\n","\n","# Predição de uma saída yi a partir de uma entrada xi\n","# Fornece a classe de saída e a probabilidade de acerto\n","out_class, out_prob = mlp.predict(xi)"],"execution_count":18,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-a72d2fe849a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'random data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Vetor xi com entradas não conhecidas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-9f134596fc4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inp, y, type)\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gradient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-9f134596fc4a>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m       \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m       \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (2,2) and (0,1) not aligned: 2 (dim 1) != 0 (dim 0)"]}]},{"cell_type":"markdown","metadata":{"id":"pqYMr4J0ZF96","colab_type":"text"},"source":["Exemplo com a tarefa XOR\n"]},{"cell_type":"code","metadata":{"id":"drU1-aQt8tFv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596073102641,"user_tz":180,"elapsed":5542,"user":{"displayName":"Carolina Alves Ribeiro","photoUrl":"https://lh6.googleusercontent.com/-PqVNf9mWVxc/AAAAAAAAAAI/AAAAAAAAAJ4/QbFQ4QxVm3g/s64/photo.jpg","userId":"07105028147325403239"}},"outputId":"859b5435-b9f1-4903-97f5-806edd8511a7"},"source":["import random\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","training_xor = [\n","    {\n","        \"input\": [0, 0],\n","        \"output\": [0]\n","    },\n","    {\n","        \"input\": [1, 0],\n","        \"output\": [1]\n","    },\n","    {\n","        \"input\": [0, 1],\n","        \"output\": [1]\n","    },\n","    {\n","        \"input\": [1, 1],\n","        \"output\": [0]\n","    }\n","]\n","def xor():\n","    # Create a MLP with 2 input, a hidden layer with 2 nodes a single output node\n","    # Criando uma MLP \n","    nn = MLP(input_nodes=2, learning_rate=.2)\n","    nn.add_layer(2)\n","    nn.add_layer(4)\n","\n","\n","    print(\"Treinando a rede\")\n","    for i in range(20000):\n","        data = random.choice(training_xor)\n","        [ws, e] = nn.train(data[\"input\"], data[\"output\"])\n","        \n","    \n","    for i in range(2):\n","        for j in range(2):\n","            out_class, out_prob = nn.predict([i, j])\n","            print(\"Predição do XOR entre {} e {} obtendo {} e o resultado real é  {} (% de acerto: {:.2f})\"\n","                  .format(i, j, out_prob > .5, bool(i) ^ bool(j), out_prob))\n","            \n","xor()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Treinando a rede\n","Predição do XOR entre 0 e 0 obtendo False e o resultado real é  False (% de acerto: 0.02)\n","Predição do XOR entre 0 e 1 obtendo True e o resultado real é  True (% de acerto: 0.51)\n","Predição do XOR entre 1 e 0 obtendo True e o resultado real é  True (% de acerto: 0.98)\n","Predição do XOR entre 1 e 1 obtendo True e o resultado real é  False (% de acerto: 0.51)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wHPmrNfTZKUC","colab_type":"text"},"source":["Exemplo com mnist dataset\n"]},{"cell_type":"code","metadata":{"id":"2TSTgkC8PnD8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596073114870,"user_tz":180,"elapsed":1830,"user":{"displayName":"Carolina Alves Ribeiro","photoUrl":"https://lh6.googleusercontent.com/-PqVNf9mWVxc/AAAAAAAAAAI/AAAAAAAAAJ4/QbFQ4QxVm3g/s64/photo.jpg","userId":"07105028147325403239"}}},"source":["def filter_pixel(x):\n","    return x / 255\n","\n","\n","def process_df(df, type=\"test\"):\n","    if type == \"train\":\n","      label = \"6\"\n","    else:\n","      label = \"7\"\n","    labels = df[label]\n","    df = df.drop([label], axis=1)\n","    df = df.apply(np.vectorize(filter_pixel))\n","    df = pd.concat([labels, df], axis=1)\n","    return df"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_lAE_oWTQR1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596073120824,"user_tz":180,"elapsed":1015,"user":{"displayName":"Carolina Alves Ribeiro","photoUrl":"https://lh6.googleusercontent.com/-PqVNf9mWVxc/AAAAAAAAAAI/AAAAAAAAAJ4/QbFQ4QxVm3g/s64/photo.jpg","userId":"07105028147325403239"}}},"source":["import pandas as pd\n","\n","def ocr(training_population=5000, testing_population=1000):\n","    print(\"Loading data...\")\n","    train = pd.read_csv('sample_data/mnist_train_small.csv')\n","    train = process_df(train, \"train\")\n","    test_set = pd.read_csv('sample_data/mnist_test.csv')\n","    test_set = process_df(test_set)\n","    print(\"Loaded {} rows for training.\".format(train.shape[0]))\n","    print(\"Loaded {} rows for testing.\".format(test_set.shape[0]))\n","    nn = MLP(input_nodes=784, learning_rate=.05)\n","    nn.add_layer(300)\n","    nn.add_layer(150)\n","    nn.add_layer(10)\n","\n","    print(\"Training the network with {} samples...\".format(training_population))\n","    for i in range(training_population):\n","        data = train.sample(n=1)\n","        label = data[\"6\"].tolist()[0]\n","        inputs = list(data.iloc[0, 1:])\n","        outputs = [0] * 10\n","        outputs[label] = 1\n","        nn.train(inputs, outputs)\n","\n","    print(\"Trained successfully.\")\n","    # nn.save(\"ocr.mlp\")\n","    print(\"Testing with {} samples...\".format(testing_population))\n","    c_m = np.zeros(shape=(10, 10))\n","    for i in range(testing_population):\n","        data = test_set.sample(n=1)\n","        inputs = list(data.iloc[0, 1:])\n","        label = data[\"7\"].tolist()[0]\n","        out_class, out_prob = nn.predict(inputs)\n","        c_m[label][out_class] += 1\n","\n","    print(\"Results:\")\n","\n","    correct_guesses = np.sum(np.diagonal(c_m))\n","    total_guesses = c_m.sum()\n","    accuracy = correct_guesses / total_guesses\n","\n","    recall = 0\n","    precision = 0\n","    c_m_t = c_m.T\n","\n","    for i in range(10):\n","        correct_guesses = c_m[i][i]\n","        total_row = np.sum(c_m[i])\n","        total_col = np.sum(c_m_t[i])\n","        recall += (correct_guesses / total_row) if total_row > 0 else 0\n","        precision += (correct_guesses / total_col) if total_col > 0 else 0\n","    \n","    recall = recall / 10\n","    precision = precision / 10\n","\n","    print(\"\\tRecall: {0:.2f}\\n\\tPrecision: {0:.2f}\\n\\tAccuracy: {0:.2f}\".format(recall, precision, accuracy))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"rSDYIW_kUfY2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1596073443813,"user_tz":180,"elapsed":316059,"user":{"displayName":"Carolina Alves Ribeiro","photoUrl":"https://lh6.googleusercontent.com/-PqVNf9mWVxc/AAAAAAAAAAI/AAAAAAAAAJ4/QbFQ4QxVm3g/s64/photo.jpg","userId":"07105028147325403239"}},"outputId":"8acb9e5f-2e46-405e-8084-d0f18419a8fb"},"source":["ocr(training_population=50000, testing_population=5000)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Loading data...\n","Loaded 19999 rows for training.\n","Loaded 9999 rows for testing.\n","Training the network with 50000 samples...\n","Trained successfully.\n","Testing with 5000 samples...\n","Results:\n","\tRecall: 0.96\n","\tPrecision: 0.96\n","\tAccuracy: 0.96\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1u0P_dHqZofY","colab_type":"text"},"source":["Baseado na implementação https://github.com/Fodark/mlp-python\n"]}]}