{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02. Felipe.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XZiHhew7E0O2","colab_type":"text"},"source":["# 1. Importações\n"]},{"cell_type":"code","metadata":{"id":"_wxwUUF1FN6l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1595242610651,"user_tz":180,"elapsed":39855,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"ef143045-3948-4016-d532-8562dd00c2a6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iYahdYA2VR8O","colab_type":"code","colab":{}},"source":["import time\n","import numpy as np\n","import pandas as pd\n","from xgboost import XGBClassifier\n","\n","from sklearn import svm\n","from sklearn.svm import SVC\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","from sklearn.metrics import make_scorer\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YqmRTenfE4HP","colab_type":"text"},"source":["# 2. Leitura dos Dados"]},{"cell_type":"code","metadata":{"id":"eCnqZdszE5cq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595242621463,"user_tz":180,"elapsed":4579,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"9a20adaa-0e39-4661-ff81-2999698bb7a7"},"source":["path = '/content/drive/My Drive/[2020.1] APRENDIZADO DE MÁQUINA/TRABALHO/02. Arquivos/01. Dados/01. Dados para treino e teste/'\n","cols = pd.read_csv(path + 'x_train.csv', nrows=1).columns\n","x_train = pd.read_csv(path + 'x_train.csv', index_col=False, usecols=cols[:-1])\n","x_test = pd.read_csv(path + 'x_test.csv', index_col=False, usecols=cols[:-1])\n","y_train = pd.read_csv(path + 'y_train.csv', index_col=False, usecols=['classification'])\n","y_test = pd.read_csv(path + 'y_test.csv', index_col=False, usecols=['classification'])\n","\n","len(x_train), len(x_test), len(y_train), len(y_test)\n","x_train.shape, x_test.shape, y_train.shape, y_test.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1106, 300), (277, 300), (1106, 1), (277, 1))"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"8VN8TG7tE51K","colab_type":"text"},"source":["# 3. SVM"]},{"cell_type":"code","metadata":{"id":"Qvf_SQ1593ZT","colab_type":"code","colab":{}},"source":["# Parâmetros para o grid search\n","param_grid = [\n","    {'kernel': ['linear'], 'C': [0.1, 50, 100]},\n","    {'kernel': ['rbf'], 'C': [0.1, 50, 100], 'gamma': [0.0001, 0.01, 1, 10] },\n","    {'kernel': ['poly'], 'C': [0.1, 50, 100], 'degree':np.arange(3, 7) }\n","]\n","\n","scoring = {\n","    'AUC': 'roc_auc', \n","    'Accuracy': make_scorer(accuracy_score)\n","}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DM7PPC89-Z5J","colab_type":"code","colab":{}},"source":["grid = GridSearchCV(SVC(),param_grid, verbose=2, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5S-HZhe7-e41","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1595213297239,"user_tz":180,"elapsed":628787,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"a3a7a783-17ed-4795-8135-151ad9794c93"},"source":["%time best_model = grid.fit(x_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  9.6min\n","[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed: 10.2min finished\n"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 18.9 s, sys: 57.9 ms, total: 18.9 s\n","Wall time: 10min 27s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8OG91i8bWX4Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1595213297240,"user_tz":180,"elapsed":626528,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"2b7567f3-60a3-4d2c-ab7a-08acc7babe32"},"source":["print(f'Best score: {best_model.best_score_}')\n","print(f'Best model: {best_model.best_params_}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Best score: 0.8237006237006236\n","Best model: {'C': 0.1, 'kernel': 'linear'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oo4lby4VW5be","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1595213363327,"user_tz":180,"elapsed":700,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"9ecf6433-ee85-4b62-9e58-7b5aae72e99c"},"source":["pred_test = best_model.predict(x_test)\n","pred_train = best_model.predict(x_train)\n","\n","print('Train Accuracy: ', accuracy_score(y_train, pred_train))\n","print('Test Accuraccy: ', accuracy_score(y_test, pred_test))\n","\n","print('\\nConfusion Matrix:')\n","print(confusion_matrix(y_test,pred_test))\n","\n","print('\\nClassification Report:')\n","report = classification_report(y_test, pred_test, output_dict=True)\n","\n","print(report)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Accuracy:  0.9385171790235082\n","Test Accuraccy:  0.8411552346570397\n","\n","Confusion Matrix:\n","[[111  19]\n"," [ 25 122]]\n","\n","Classification Report:\n","{'0': {'precision': 0.8161764705882353, 'recall': 0.8538461538461538, 'f1-score': 0.8345864661654135, 'support': 130}, '1': {'precision': 0.8652482269503546, 'recall': 0.8299319727891157, 'f1-score': 0.8472222222222222, 'support': 147}, 'accuracy': 0.8411552346570397, 'macro avg': {'precision': 0.8407123487692949, 'recall': 0.8418890633176348, 'f1-score': 0.8409043441938179, 'support': 277}, 'weighted avg': {'precision': 0.8422181607876271, 'recall': 0.8411552346570397, 'f1-score': 0.8412920840006153, 'support': 277}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WMA3dX-ASvfO","colab":{}},"source":["resultados = pd.DataFrame({\n","    'precision': report['weighted avg']['precision'], \n","    'recall': report['weighted avg']['recall'],\n","    'f1score': report['weighted avg']['f1-score'],\n","    'y_predict': [pred_test],\n","    'y_real': [y_test['classification'].values],\n","    'hiperparams': str(best_model.best_params_)\n","})\n","resultados.to_json('/content/drive/My Drive/[2020.1] APRENDIZADO DE MÁQUINA/TRABALHO/05. Resultados/5.1. Resultados dos modelos/7. SVM/svm.json')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJRBBtoyOe0_","colab_type":"text"},"source":["# 4. XGBoostClassifier\n","**Necessário habilitar a GPU para executar**\n"]},{"cell_type":"code","metadata":{"id":"eBqMZH7U733G","colab_type":"code","colab":{}},"source":["# create a default XGBoost classifier\n","model = XGBClassifier(\n","    tree_method = \"gpu_hist\", \n","    random_state=300, \n","    eval_metric=[\"error\", \"auc\"]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hu7_D7Uc74mo","colab_type":"code","colab":{}},"source":["# Create the grid search parameter grid and scoring funcitons\n","param_grid = {\n","    \"learning_rate\": [0.1, 0.01],\n","    \"colsample_bytree\": [0.6, 0.8, 1.0],\n","    \"subsample\": [0.6, 0.8, 1.0],\n","    \"max_depth\": [2, 3, 4],\n","    \"n_estimators\": [100, 200, 300, 400],\n","    \"reg_lambda\": [1, 1.5, 2],\n","    \"gamma\": [0, 0.1, 0.3],\n","}\n","scoring = {\n","    'AUC': 'roc_auc', \n","    'Accuracy': make_scorer(accuracy_score)\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_gsShh6Fj-e","colab_type":"code","colab":{}},"source":["gridXGB = GridSearchCV(model,param_grid, verbose=2, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKdHa0CwI0Cf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":294},"outputId":"56afe410-f280-4401-db89-66b03d2a7d9a"},"source":["# fit grid search\n","%time best_model = gridXGB.fit(x_train,y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   27.9s\n","[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.7min\n","[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  9.6min\n","[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed: 17.2min\n","[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 27.6min\n","[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 40.7min\n","[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 55.8min\n","[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 72.7min\n","[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 93.3min\n","[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 114.5min\n","[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 140.4min\n","[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed: 166.7min\n","[Parallel(n_jobs=-1)]: Done 6841 tasks      | elapsed: 196.7min\n","[Parallel(n_jobs=-1)]: Done 7934 tasks      | elapsed: 228.4min\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xkBBfdz38jUe","colab_type":"code","colab":{}},"source":["print(f'Best score: {best_model.best_score_}')\n","print(f'Best model: {best_model.best_params_}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7T5UU_RMx8K_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":155},"executionInfo":{"status":"ok","timestamp":1595262819956,"user_tz":180,"elapsed":1264,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"6d284d01-dace-44b8-b83c-32b215633d2f"},"source":["{\n","    'Best score': 0.8499408911173617,\n","    'Best model': {'colsample_bytree': 0.6, 'gamma': 0.3, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 400, 'reg_lambda': 1, 'subsample': 0.6}\n","}"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Best model': {'colsample_bytree': 0.6,\n","  'gamma': 0.3,\n","  'learning_rate': 0.1,\n","  'max_depth': 2,\n","  'n_estimators': 400,\n","  'reg_lambda': 1,\n","  'subsample': 0.6},\n"," 'Best score': 0.8499408911173617}"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"WKMJBbuG8--1","colab_type":"code","colab":{}},"source":["pred_test = best_model.predict(x_test)\n","pred_train = best_model.predict(x_train)\n","print('Train Accuracy: ', accuracy_score(y_train, pred_train))\n","print('Test Accuraccy: ', accuracy_score(y_test, pred_test))\n","print('\\nConfusion Matrix:')\n","print(confusion_matrix(y_test,pred_test))\n","print('\\nClassification Report:')\n","report = classification_report(y_test, pred_test, output_dict=True)\n","print(report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jIDnzZYREupU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1595262892037,"user_tz":180,"elapsed":678,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"fcb5e139-b97b-4cee-ac91-91ae3fc54537"},"source":["{'Train Accuracy':  0.9963833634719711,\n","'Test Accuraccy':  0.8664259927797834,\n","\n","'Confusion Matrix':\n","[[115,  15], [ 22, 125]],\n","\n","'Classification Report':\n","{'0': {'precision': 0.8394160583941606, 'recall': 0.8846153846153846, 'f1-score': 0.8614232209737828, 'support': 130}, '1': {'precision': 0.8928571428571429, 'recall': 0.8503401360544217, 'f1-score': 0.8710801393728222, 'support': 147}, 'accuracy': 0.8664259927797834, 'macro avg': {'precision': 0.8661366006256517, 'recall': 0.8674777603349031, 'f1-score': 0.8662516801733025, 'support': 277}, 'weighted avg': {'precision': 0.8677764894990645, 'recall': 0.8664259927797834, 'f1-score': 0.8665480116043199, 'support': 277}}\n","}"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Classification Report': {'0': {'f1-score': 0.8614232209737828,\n","   'precision': 0.8394160583941606,\n","   'recall': 0.8846153846153846,\n","   'support': 130},\n","  '1': {'f1-score': 0.8710801393728222,\n","   'precision': 0.8928571428571429,\n","   'recall': 0.8503401360544217,\n","   'support': 147},\n","  'accuracy': 0.8664259927797834,\n","  'macro avg': {'f1-score': 0.8662516801733025,\n","   'precision': 0.8661366006256517,\n","   'recall': 0.8674777603349031,\n","   'support': 277},\n","  'weighted avg': {'f1-score': 0.8665480116043199,\n","   'precision': 0.8677764894990645,\n","   'recall': 0.8664259927797834,\n","   'support': 277}},\n"," 'Confusion Matrix': [[115, 15], [22, 125]],\n"," 'Test Accuraccy': 0.8664259927797834,\n"," 'Train Accuracy': 0.9963833634719711}"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"6if4DPs3I_W_","colab_type":"text"},"source":["# Salvando os resultados\n"]},{"cell_type":"code","metadata":{"id":"fyLLZRHfI2oU","colab_type":"code","colab":{}},"source":["resultados = pd.DataFrame({\n","    'precision': report['weighted avg']['precision'], \n","    'recall': report['weighted avg']['recall'],\n","    'f1score': report['weighted avg']['f1-score'],\n","    'y_predict': [pred_test],\n","    'y_real': [y_test['classification'].values],\n","    'hiperparams': str(best_model.best_params_)\n","})\n","resultados.to_json('/content/drive/My Drive/[2020.1] APRENDIZADO DE MÁQUINA/TRABALHO/05. Resultados/5.1. Resultados dos modelos/10. XGBooster/xgbooster.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kz_k0CzlLLL5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"ok","timestamp":1595047515418,"user_tz":180,"elapsed":966,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"4b59eea2-3292-4c0d-955b-63ed2aba2e32"},"source":["{'0': {'precision': 0.8444444444444444, 'recall': 0.8769230769230769, 'f1-score': 0.860377358490566, 'support': 130}, '1': {'precision': 0.8873239436619719, 'recall': 0.8571428571428571, 'f1-score': 0.8719723183391004, 'support': 147}, 'accuracy': 0.8664259927797834, 'macro avg': {'precision': 0.8658841940532082, 'recall': 0.8670329670329671, 'f1-score': 0.8661748384148331, 'support': 277}, 'weighted avg': {'precision': 0.8671999909606052, 'recall': 0.8664259927797834, 'f1-score': 0.8665306404318459, 'support': 277}}"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0': {'f1-score': 0.860377358490566,\n","  'precision': 0.8444444444444444,\n","  'recall': 0.8769230769230769,\n","  'support': 130},\n"," '1': {'f1-score': 0.8719723183391004,\n","  'precision': 0.8873239436619719,\n","  'recall': 0.8571428571428571,\n","  'support': 147},\n"," 'accuracy': 0.8664259927797834,\n"," 'macro avg': {'f1-score': 0.8661748384148331,\n","  'precision': 0.8658841940532082,\n","  'recall': 0.8670329670329671,\n","  'support': 277},\n"," 'weighted avg': {'f1-score': 0.8665306404318459,\n","  'precision': 0.8671999909606052,\n","  'recall': 0.8664259927797834,\n","  'support': 277}}"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"Lzzyr2JHNWYr","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"DKo-5ODH8e0S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"status":"error","timestamp":1595226395325,"user_tz":180,"elapsed":12606107,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"65320925-ddf3-40e6-d59e-531c5d8f78be"},"source":["'''num_folds = 10\n","kfold = StratifiedKFold(n_splits=num_folds)\n","\n","# create the grid search object\n","n_iter=50\n","grid = RandomizedSearchCV(\n","    estimator=model, \n","    param_distributions=param_grid,\n","    scoring=scoring,\n","    cv=kfold,\n","    n_jobs=-1,\n","    n_iter=n_iter,\n","    refit=\"AUC\",\n",")\n","num_folds = 10\n","kfold = StratifiedKFold(n_splits=num_folds)\n","\n","# create the grid search object\n","n_iter=50\n","grid = RandomizedSearchCV(\n","    estimator=model, \n","    param_distributions=param_grid,\n","    scoring=scoring,\n","    cv=kfold,\n","    n_jobs=-1,\n","    n_iter=n_iter,\n","    refit=\"AUC\",\n",")'''"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-46c7a756e848>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    )''\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"]}]},{"cell_type":"code","metadata":{"id":"ALjXyaS97_az","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595277750194,"user_tz":180,"elapsed":1039,"user":{"displayName":"Felipe Marcel","photoUrl":"","userId":"15473077194179917160"}},"outputId":"2092c787-abed-48ba-92c9-791aa0c76a19"},"source":["y_pred = [1,0,0,1,1,1,1,0,0,0,1,0,0,1,1,0,1,0,1,1,0,1,0,0,1,0,0,0,1,0,0,0,0,0,1,1,1,1,0,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,0,0,0,1,0,0,0,1,0,1,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,0,1,0,1,0,0,1,1,0,1,0,1,1,1,1,1,1,0,1,0,0,0,0,0,1,0,0,0,1,1,1,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,0,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,1,1,0,1,1,1,0,0,1,0,0,0,1,1,0,1,0,1,1,0,0,1,1,0,1,1,0,0,1,1,0,0,1,0,1,0,1,0,1,1,0,1,1,0,0,0,1,0,1,0,1,0,0,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,1,1,0,1,1,0,0,1,0,1,0,0,0,1,0,0,0,0,1,1,0,0,1,1,1,1,1,0,1,0,0,0,0,0,1,0,0,0,1,1,1,1,1,1,0,0,1,1,0,1,0,1,1,0,1,0,0,1]\n","y_real = [1,0,0,1,0,0,1,0,0,0,1,0,0,1,0,0,1,0,1,1,0,1,1,0,1,1,0,0,1,0,0,0,0,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,0,1,1,1,0,1,0,0,1,1,0,0,0,1,0,1,0,1,0,0,1,1,1,1,1,1,0,0,1,1,0,1,1,0,0,1,1,0,1,0,1,0,0,1,1,0,1,0,1,1,1,1,1,1,0,0,0,1,0,0,0,1,0,0,0,0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,0,0,0,1,1,0,1,0,1,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,0,1,0,1,1,0,0,1,1,1,0,0,0,1,0,1,1,1,0,0,1,0,0,1,0,0,1,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,1,0,1,1,0,1,0,0,1,1,0,0,0,0,1,1,0,0,1,1,0,1,1,0,1,0,0,0,0,0,1,0,0,0,1,1,1,1,1,1,0,0,1,1,0,0,0,1,1,0,1,1,0,1]\n","\n","\n","print('Test Accuraccy: ', accuracy_score(y_real, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Accuraccy:  0.8664259927797834\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B5E45AHd9Rok","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}